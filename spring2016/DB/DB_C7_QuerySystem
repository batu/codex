22.02.2016

Query Systems Cont.

There exists iterators.

Scan operation:
cursor
filename := heapfile
open(){
	open(filename);
	cursor to first position
	page #, offset
}
close(){

}

hasNext(){
if cursor not @ end of file:
	return true
else:
	return 
}

next(){
	t = tuple@cursor
	forward cursor
	return t;
}

project - filter - scan - tuple (this is called pipeline, instead of the whole table)

Sometimes you cant do that for example in a sort.

Bushy VS Left deep.

Bushy


		x
	X		X
    A      B       C        D

hard to pipeline beacuse it has to store one join table or recompute every time. 


Left Deep

				X
			X           D
		X          C 
	    A      B

Here you dont have to save any tables. You get a table, compare with a tuple. 

Useful because you can chain stuff. 

Optimizer
-Heuristics
-Cost based

What causes cost?
-Loops
-IO (read and writes)
-IO (network)

Units. Time per tuple/

You try to figure out where the bottleneck is?
-you need to balance stuff. 100% CPU and 20% disk you know where the problem is.


The Time Graph

1 	ns	as instruction
100 	ns 	accessing memory
10	ms	Disk Seek
20	ms	Read 1mb sequentially from disk


CPU - 1ns/op
I/O - 10ns/byte (just reading assumign seeked)
Random I/O - (1pg read + 1 seek) = 10ms/seek

seek 1 byte = waste 1000000 ops!

Generally the bottleneck is the disk.



1 page = 10kb = 100 tuples
tuple = 100 byte
Memory fits 10 pages
10ms seek time
100MB/sec I/O
100 houses = 1 page
10K faculty = 100 pages
30k children = 300 pages



Nested Loop

		X
	A		B
      Outer 	      Inner

for every To in outer:
	for every Ti in inner
		if(pred(To,Ti);
			emit(to,ti);


	X
Houter	   Finner


CPU Cost
	100 x 10K

IO Cost
	(1+100) 101 seeks
	(2+100) 
	100 x 100

	X
Fouter	   Hinner

IO
	(100 seek for faculty)
	(1 seek for housing)
	100 x 1
Because you dont have to evict the house from the buffer.

General rule is that small table is inner. Especially if you can fit in the memory.
If you cant fit it in then memory the block stuff.

Some caching procedures will change will stuff.


-----------------------------------------------------------------
Class 8

Prefetch

Bandwith I/O = 100MB/s
Seek Time = 10ms

Computational Cost = 10k x 100 in any arrangement
-Disk bandwith << CPU Bandwith
!! Not always the case !! 



	X
Houter		Finner

Houses
100 X ( seektime +  readtime)
100 x ( 10ms + 10Kb/ 100Mb/s)
100 X ( 10ms + 0.1ms)

Faculty

100 X ( 10ms + (100x10Kb) / 100MB/s)


	X
Fouter		Hinner

1st read (10ms + 10KB / 100MB/s) - faculty
2st read (10ms + 10KB / 100MB/s) - housing

10ms + (10KB X 99) / 100MB/s

100x faster.

100 houses
10k Faculty
30k children

You dont have to wait F X H to finish to start comparing to C. Pipelining.


Left is Outer Right is inner

		X
	X(filter)     	C
     F     H

Left deep



	X
C		X
	     F     H

Right deep. In this case it needs to compute the righter join every time or store it somewhere


DBMin:
Eviction policy
Buffer management.


4 Pages but only 3 Mpgs available.

LRU (Last Recent Used)
123 423 413 412 etc no hits

MRU (Most Recent Used)
123 124 (1 and 2 is hit!) 123 124 (1 and 2 is hit) 123

buffer
PG ID | Locks | Pts(which points to memmory)

DBMIN : Different policies per access method per file.
	Aka different policies per file instance. 

List different access patterns:

-Sequential Scan
-Random Access Hierarchical)

-Looping  (over and over again, keep the data in buffer)
-Straight (only once, no need to keep das data)

-Clustered (helps when the thing is sorted)

StraightHierarchical  - 1pg / NA

LoopingSequential - min(how much I can allocate/page size) / MRU

LoopingHierarchical - as many pages for index(top levels)  /

StraightSequential - 1pg / NA 

Double buffering is a problem. DB gets pages to buffer. OS also buffers. WASTE.
Be too smart. Even if you want 1 page, it can prefetch a lot.
Write to a page in buffer and you flush it to disk. OS also controls it and it doesnt always flush it instantly. So you think its saved but isnt.

























